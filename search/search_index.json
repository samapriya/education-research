{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This page and training materials are designed for education and research purposes only. The core component of the training include but are not limited to: Introduction to Planet data Downloading Planet data Planet API(s) Introduction to Google Earth Engine Planet data analytics in Google Earth Engine","title":"Introduction"},{"location":"#introduction","text":"This page and training materials are designed for education and research purposes only. The core component of the training include but are not limited to: Introduction to Planet data Downloading Planet data Planet API(s) Introduction to Google Earth Engine Planet data analytics in Google Earth Engine","title":"Introduction"},{"location":"citations/","text":"Citations From concept to actual tools and insights, much have gone into creating these platforms and I hope you will cite them as needed. To cite Planet data in publications, please use the following: Planet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA. https://api.planet.com. To cite Google Earth Engine, use the following: Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment 202 (2017): 18-27.","title":"Citations"},{"location":"citations/#citations","text":"From concept to actual tools and insights, much have gone into creating these platforms and I hope you will cite them as needed. To cite Planet data in publications, please use the following: Planet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA. https://api.planet.com. To cite Google Earth Engine, use the following: Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment 202 (2017): 18-27.","title":"Citations"},{"location":"contact/","text":"Contact Us Reach out for suppport to Ask questions on our community page","title":"Contact Us"},{"location":"contact/#contact-us","text":"Reach out for suppport to Ask questions on our community page","title":"Contact Us"},{"location":"projects/data_api/","text":"Data API Data API is the core API that you will deal with in this workshop. For the most part , the Data API allows you to search for Datasets, activate and download images. You can find entire API reference here and we will access most of the functionality using the Planet Client. The API is self descriptive and allows you to read about specs, items and asset types. You can exlore the data endpoint, by using this webaddress in chrome, use your API key as username and leave password blank https : //api.planet.com/data/v1/","title":"Data API"},{"location":"projects/data_api/#data-api","text":"Data API is the core API that you will deal with in this workshop. For the most part , the Data API allows you to search for Datasets, activate and download images. You can find entire API reference here and we will access most of the functionality using the Planet Client. The API is self descriptive and allows you to read about specs, items and asset types. You can exlore the data endpoint, by using this webaddress in chrome, use your API key as username and leave password blank https : //api.planet.com/data/v1/","title":"Data API"},{"location":"projects/downloading-images/","text":"Downloading Planet Images You can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery. Planet Explorer Planet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order. Steps to get satellite imagery from Planet Explorer Once the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you. To interact with the Data API and batch download imagery there is host of Planet Platform documentation that teach you how to do that step by step. Batch Download Images Using Planet Python CLI This is the default command line tool that is provided by planet and you can find the project here and it connects to Data API to perform multiple operations such as quick search, activate and download assets among a few other things. Install it easily using pip install planet follow it by planet init to initialize and you are ready to go. A simple setup to download images using a geometry(a simple geometry geojson file) and date range (let us say between 2018-07-01 to 2018-08-31), cloud cover(less than 10% or less than 0.1) could be achieved in a single line of cli command planet data download --item-type PSScene4Band --geom full path to geometry.geojson --date acquired gt 2018-07-01 --date acquired lt 2018-08-31 --range cloud_cover lt 0.1 --asset-type analytic --dest your local directory path Using Planet's OrdersV2 Using Ordersv2 to download images allows for better order experience .","title":"Downloading Planet Images"},{"location":"projects/downloading-images/#downloading-planet-images","text":"You can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery.","title":"Downloading Planet Images"},{"location":"projects/downloading-images/#planet-explorer","text":"Planet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order. Steps to get satellite imagery from Planet Explorer Once the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you. To interact with the Data API and batch download imagery there is host of Planet Platform documentation that teach you how to do that step by step.","title":"Planet Explorer"},{"location":"projects/downloading-images/#batch-download-images","text":"","title":"Batch Download Images"},{"location":"projects/downloading-images/#using-planet-python-cli","text":"This is the default command line tool that is provided by planet and you can find the project here and it connects to Data API to perform multiple operations such as quick search, activate and download assets among a few other things. Install it easily using pip install planet follow it by planet init to initialize and you are ready to go. A simple setup to download images using a geometry(a simple geometry geojson file) and date range (let us say between 2018-07-01 to 2018-08-31), cloud cover(less than 10% or less than 0.1) could be achieved in a single line of cli command planet data download --item-type PSScene4Band --geom full path to geometry.geojson --date acquired gt 2018-07-01 --date acquired lt 2018-08-31 --range cloud_cover lt 0.1 --asset-type analytic --dest your local directory path","title":"Using Planet Python CLI"},{"location":"projects/downloading-images/#using-planets-ordersv2","text":"Using Ordersv2 to download images allows for better order experience .","title":"Using Planet's OrdersV2"},{"location":"projects/edges/","text":"Edge Detection You can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications. Similar to earlier example you can access the full script here or copy and past the same code into code.earthengine.google.com //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add image and visualization var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; var ndvi = image . normalizedDifference ([ b4 , b3 ]); // Apply a Canny edge detector. var canny = ee . Algorithms . CannyEdgeDetector ({ image : ndvi , threshold : 0.2 }). multiply ( 255 ); // Apply the Hough transform. var h = ee . Algorithms . HoughTransform ({ image : canny , gridSize : 256 , inputThreshold : 80 , lineThreshold : 80 }); // Display. Map . addLayer ( image , vis , source_image ); Map . addLayer ( ndvi ,{ min : - 0.05 , max : 0.5 }, NDVI , false ) Map . addLayer ( canny . updateMask ( canny ), { min : 0 , max : 1 , palette : blue }, canny ); Map . addLayer ( h . updateMask ( h ), { min : 0 , max : 1 , palette : red }, hough ); Map . setOptions ( SATELLITE )","title":"Edge Detection"},{"location":"projects/edges/#edge-detection","text":"You can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications. Similar to earlier example you can access the full script here or copy and past the same code into code.earthengine.google.com //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add image and visualization var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; var ndvi = image . normalizedDifference ([ b4 , b3 ]); // Apply a Canny edge detector. var canny = ee . Algorithms . CannyEdgeDetector ({ image : ndvi , threshold : 0.2 }). multiply ( 255 ); // Apply the Hough transform. var h = ee . Algorithms . HoughTransform ({ image : canny , gridSize : 256 , inputThreshold : 80 , lineThreshold : 80 }); // Display. Map . addLayer ( image , vis , source_image ); Map . addLayer ( ndvi ,{ min : - 0.05 , max : 0.5 }, NDVI , false ) Map . addLayer ( canny . updateMask ( canny ), { min : 0 , max : 1 , palette : blue }, canny ); Map . addLayer ( h . updateMask ( h ), { min : 0 , max : 1 , palette : red }, hough ); Map . setOptions ( SATELLITE )","title":"Edge Detection"},{"location":"projects/functions/","text":"Functions in Earth Engine: NDVI While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed You can access the script here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to the AOI Map . centerObject ( aoi , 13 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.2 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI )","title":"Functions in Earth Engine"},{"location":"projects/functions/#functions-in-earth-engine-ndvi","text":"While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed You can access the script here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to the AOI Map . centerObject ( aoi , 13 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.2 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI )","title":"Functions in Earth Engine: NDVI"},{"location":"projects/getting-images-ee/","text":"Getting Images into Google Earth Engine For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"Getting Images into Google Earth Engine"},{"location":"projects/getting-images-ee/#getting-images-into-google-earth-engine","text":"For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"Getting Images into Google Earth Engine"},{"location":"projects/housekeeping/","text":"Housekeeping and Setup For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with 1) Planet Command Line Interface(CLI) Setup You planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple pip install planet You installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client . Here's a medium article that discusses Planet's command line tool and gives you a jump start 2) Location to GEE datasets For the purpose of this workshop, I have downloaded and ingested Planet 4Band Surface Reflectance imagery into an earth engine image colllection. The included data is maintained as open access license granted by the Open California Program. you can add any of the datasets by simply adding the following lines to the code editor. For now you access these here, open directly //Add image collection and area of interest var collection = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) var aoi = ee . FeatureCollection ( projects/sat-io/open-ca/aoi ) //get size of collection print ( PlanetScope SR , collection . size ()) //Get the first element from each collection print ( PSR Image , collection . first ()) for those using Google Earth Engine python API you can still access a collection import ee ee . Initialize () collection = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) ##Check how many images does the collection have print ( collection . size () . getInfo ()) ## Print metadata from the first image print ( collection . first () . getInfo ()) 3) Adding additional Images For a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE. For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here 5) Additional Tools and Toolboxes for Local Analysis If you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here ENVI Integration ESRI Integration Cesium Integration Boundless PCI Geomatics","title":"Basic Housekeeping and Setup"},{"location":"projects/housekeeping/#housekeeping-and-setup","text":"For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with","title":"Housekeeping and Setup"},{"location":"projects/housekeeping/#1-planet-command-line-interfacecli-setup","text":"You planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple pip install planet You installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client . Here's a medium article that discusses Planet's command line tool and gives you a jump start","title":"1) Planet Command Line Interface(CLI) Setup"},{"location":"projects/housekeeping/#2-location-to-gee-datasets","text":"For the purpose of this workshop, I have downloaded and ingested Planet 4Band Surface Reflectance imagery into an earth engine image colllection. The included data is maintained as open access license granted by the Open California Program. you can add any of the datasets by simply adding the following lines to the code editor. For now you access these here, open directly //Add image collection and area of interest var collection = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) var aoi = ee . FeatureCollection ( projects/sat-io/open-ca/aoi ) //get size of collection print ( PlanetScope SR , collection . size ()) //Get the first element from each collection print ( PSR Image , collection . first ()) for those using Google Earth Engine python API you can still access a collection import ee ee . Initialize () collection = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) ##Check how many images does the collection have print ( collection . size () . getInfo ()) ## Print metadata from the first image print ( collection . first () . getInfo ())","title":"2) Location to GEE datasets"},{"location":"projects/housekeeping/#3-adding-additional-images","text":"For a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE. For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"3) Adding additional Images"},{"location":"projects/housekeeping/#5-additional-tools-and-toolboxes-for-local-analysis","text":"If you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here ENVI Integration ESRI Integration Cesium Integration Boundless PCI Geomatics","title":"5) Additional Tools and Toolboxes for Local Analysis"},{"location":"projects/imagecollection/","text":"Image Collections in Earth Engine While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var filtered = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for June to July End print ( Date Filter Only , filtered . size ()) var filtered = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for June to July End . filterMetadata ( cloud_cover , less_than , 0.1 ) //Cloud cover less than 10% print ( Multi Filter , filtered . size ()) To have a look at all of the raster catalog you can find them listed here or you can try the list I update every week","title":"Image Collection"},{"location":"projects/imagecollection/#image-collections-in-earth-engine","text":"While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var filtered = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for June to July End print ( Date Filter Only , filtered . size ()) var filtered = ee . ImageCollection ( projects/sat-io/open-ca/ps4bsr ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for June to July End . filterMetadata ( cloud_cover , less_than , 0.1 ) //Cloud cover less than 10% print ( Multi Filter , filtered . size ()) To have a look at all of the raster catalog you can find them listed here or you can try the list I update every week","title":"Image Collections in Earth Engine"},{"location":"projects/img/","text":"Images in Earth Engine In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them //Setting up a Geometry var geometry = ee . FeatureCollection ( users/io-work-1/vector/openca ) //PlanetScope is 4 band imagery, we are adding surface reflectance image with visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min : 208 , max : 2385 , gamma : 1 }; //Add an image var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) print ( Single Image , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 12 ) Map . addLayer ( image , vis , Image ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , Clipped Image ) //Change BaseMap to Satellite Map . setOptions ( SATELLITE )","title":"Images"},{"location":"projects/img/#images-in-earth-engine","text":"In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them //Setting up a Geometry var geometry = ee . FeatureCollection ( users/io-work-1/vector/openca ) //PlanetScope is 4 band imagery, we are adding surface reflectance image with visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min : 208 , max : 2385 , gamma : 1 }; //Add an image var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) print ( Single Image , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 12 ) Map . addLayer ( image , vis , Image ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , Clipped Image ) //Change BaseMap to Satellite Map . setOptions ( SATELLITE )","title":"Images in Earth Engine"},{"location":"projects/lab/","text":"Labs Method 1: Launch JupyterLab Locally This assumes you can launch jupyterlab on your machine and we are using Python 3. There are a couple of ways to launch this clone the master branch git clone https://github.com/samapriya/education-research.git Unzip the folder and launch jupyter lab locally by simply typing jupyter lab Method 2: Launch JupyterLab on BinderHub Open this link in a new tab This allows you to run the analysis remotely and handles dependencies Binder run launches a jupyterhub instance but you can easily convert that to jupyterlab by replacing the trailing /tree with /lab","title":"Lab space"},{"location":"projects/lab/#labs","text":"","title":"Labs"},{"location":"projects/lab/#method-1-launch-jupyterlab-locally","text":"This assumes you can launch jupyterlab on your machine and we are using Python 3. There are a couple of ways to launch this clone the master branch git clone https://github.com/samapriya/education-research.git Unzip the folder and launch jupyter lab locally by simply typing jupyter lab","title":"Method 1: Launch JupyterLab Locally"},{"location":"projects/lab/#method-2-launch-jupyterlab-on-binderhub","text":"Open this link in a new tab This allows you to run the analysis remotely and handles dependencies Binder run launches a jupyterhub instance but you can easily convert that to jupyterlab by replacing the trailing /tree with /lab","title":"Method 2: Launch JupyterLab on BinderHub"},{"location":"projects/labs/","text":"","title":"Labs"},{"location":"projects/labs_ee/","text":"If you have a Google Earth Engine account, accept this repository . The tutorials are generalized and the repo contains more specific tutorials for PlanetScope image collection.","title":"Labs"},{"location":"projects/orders/","text":"Orders v2 API Ordersv2 is the next iteration of Planet's API in getting Analysis Ready Data (ARD) delivered to you. Orders v2 allows you to improved functionality in this domain, including capability to submit an number of images in a batch order, and perform operations such as top of atmospheric reflectance, compression, coregistration and also enhanced notifications such as email and webhooks.You can find the API overview and reference here . This is not yet integrated into a client but you can make the requests using clients like Postman or ARC. The API unlike data API is not self descriptive and results will only appear once you have placed an order. You can exlore the data endpoint, by using this webaddress in chrome, use your API key as username and leave password blank https : //api.planet.com/compute/ops/orders/v2 Order Up: Using and Building with Planet \u2019s new Ordersv2 API I did create a simple command line inteface (CLI) called porder to access this API and chain together tools, you can read about the tool and the tutorial here . This tool is in no way an official tool or Planet offering, but is a personal project created and maintained by me. You can find it on GitHub here and once you install it try running porder readme it should open up a new browser window with tutorials on using this tool or go here directly .","title":"Ordersv2 API"},{"location":"projects/orders/#orders-v2-api","text":"Ordersv2 is the next iteration of Planet's API in getting Analysis Ready Data (ARD) delivered to you. Orders v2 allows you to improved functionality in this domain, including capability to submit an number of images in a batch order, and perform operations such as top of atmospheric reflectance, compression, coregistration and also enhanced notifications such as email and webhooks.You can find the API overview and reference here . This is not yet integrated into a client but you can make the requests using clients like Postman or ARC. The API unlike data API is not self descriptive and results will only appear once you have placed an order. You can exlore the data endpoint, by using this webaddress in chrome, use your API key as username and leave password blank https : //api.planet.com/compute/ops/orders/v2","title":"Orders v2 API"},{"location":"projects/orders/#order-up-using-and-building-with-planet-s-new-ordersv2-api","text":"I did create a simple command line inteface (CLI) called porder to access this API and chain together tools, you can read about the tool and the tutorial here . This tool is in no way an official tool or Planet offering, but is a personal project created and maintained by me. You can find it on GitHub here and once you install it try running porder readme it should open up a new browser window with tutorials on using this tool or go here directly .","title":"Order Up: Using and Building with Planet \u2019s new Ordersv2 API"},{"location":"projects/planet-asset/","text":"Understand Planet Items-Assets API You can read the most updated white paper on planet products, items, assets and specifications here . While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy Planet Imagery Product Offerings Items and Assets Item type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis. Asset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it. For further reference on item asset relationships you can visit the docs Now the assumption here is that after you have created your account you have downloaded data either from Planet Explorer or you have been curious and looked into the data API and used the wonderful python client from planet. Incase you have not and you have python on your system, invoke the power of pip and type pip install planet","title":"Planet Imagery"},{"location":"projects/planet-asset/#understand-planet-items-assets-api","text":"You can read the most updated white paper on planet products, items, assets and specifications here . While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy Planet Imagery Product Offerings","title":"Understand Planet Items-Assets &amp; API"},{"location":"projects/planet-asset/#items-and-assets","text":"Item type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis. Asset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it. For further reference on item asset relationships you can visit the docs Now the assumption here is that after you have created your account you have downloaded data either from Planet Explorer or you have been curious and looked into the data API and used the wonderful python client from planet. Incase you have not and you have python on your system, invoke the power of pip and type pip install planet","title":"Items and Assets"},{"location":"projects/reducers/","text":"Reducers Charts in Earth Engine While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. Source: Image Collection Reductions from Google Earth Engine For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. The last step we create a setup for the chart and the plot the chart of the median /*Add some field points and name the geometry as field this script won t work till then*/ //Add an image collection var collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR ) //Filtering an Image Collection var filtered = collection . filterMetadata ( WRS_PATH , equals , 25 ) . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 ) //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ B4 , B3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.5182320475578308 , max : 0.7803871631622314 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the first of the result Map . addLayer ( ee . Image ( ndvicoll . first ()), ndvivis , NDVI ) //Add an reducer var ndviav = ndvicoll . reduce ( ee . Reducer . median ()); Map . addLayer ( ndviav . select ( NDVI_median ). rename ( NDVI ), ndvivis , NDVI Median ) print ( ndviav ) Top: Field points to look at median NDVI, Bottom: Chart generated from field point var ndvionly = ndviav . select ( NDVI_median ). rename ( NDVI ) var chart = ui . Chart . image . byRegion ({ image : ndvionly , regions : field , scale : 30 }); chart . setOptions ({ title : Charting NDVI , vAxis : { title : NDVI }, legend : none , lineWidth : 1 , pointSize : 4 }); print ( chart );","title":"Reducers and Charts"},{"location":"projects/reducers/#reducers-charts-in-earth-engine","text":"While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. Source: Image Collection Reductions from Google Earth Engine For this setup we look at how we added Landsat 5 Surface Reflectance data earlier , filtering it using WRS Path and Row and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. The last step we create a setup for the chart and the plot the chart of the median /*Add some field points and name the geometry as field this script won t work till then*/ //Add an image collection var collection = ee . ImageCollection ( LANDSAT/LT05/C01/T1_SR ) //Filtering an Image Collection var filtered = collection . filterMetadata ( WRS_PATH , equals , 25 ) . filterMetadata ( WRS_ROW , equals , 39 ). filterMetadata ( CLOUD_COVER , less_than , 5 ) //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ B4 , B3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.5182320475578308 , max : 0.7803871631622314 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the first of the result Map . addLayer ( ee . Image ( ndvicoll . first ()), ndvivis , NDVI ) //Add an reducer var ndviav = ndvicoll . reduce ( ee . Reducer . median ()); Map . addLayer ( ndviav . select ( NDVI_median ). rename ( NDVI ), ndvivis , NDVI Median ) print ( ndviav ) Top: Field points to look at median NDVI, Bottom: Chart generated from field point var ndvionly = ndviav . select ( NDVI_median ). rename ( NDVI ) var chart = ui . Chart . image . byRegion ({ image : ndvionly , regions : field , scale : 30 }); chart . setOptions ({ title : Charting NDVI , vAxis : { title : NDVI }, legend : none , lineWidth : 1 , pointSize : 4 }); print ( chart );","title":"Reducers &amp; Charts in Earth Engine"},{"location":"projects/rpl/","text":"Registering for a Planet account What you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary at this spatial and temporal resolution. You can find more information about the Open California project here . These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative. If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here Sign up for a Planet Account Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit planet.com/explorer . From there, click Sign Up and enter your email address to receive an invitation: Sign up with Planet Explorer Check your email follow the directions to complete the registration process. Find your API Key To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key) Registering for a Google Earth Engine Account If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page. Getting Help with Planet and Google Earth Engine Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here and offcourse the Earth Engine Developers Page","title":"Registering for a Planet account"},{"location":"projects/rpl/#registering-for-a-planet-account","text":"What you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary at this spatial and temporal resolution. You can find more information about the Open California project here . These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative. If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here","title":"Registering for a Planet account"},{"location":"projects/rpl/#sign-up-for-a-planet-account","text":"Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit planet.com/explorer . From there, click Sign Up and enter your email address to receive an invitation: Sign up with Planet Explorer Check your email follow the directions to complete the registration process.","title":"Sign up for a Planet Account"},{"location":"projects/rpl/#find-your-api-key","text":"To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key)","title":"Find your API Key"},{"location":"projects/rpl/#registering-for-a-google-earth-engine-account","text":"If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.","title":"Registering for a Google Earth Engine Account"},{"location":"projects/rpl/#getting-help-with-planet-and-google-earth-engine","text":"Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here and offcourse the Earth Engine Developers Page","title":"Getting Help with Planet and Google Earth Engine"},{"location":"projects/setup/","text":"Registering for a Planet account What you need first to get started in simply to register for a Planet account. Basic Account To sign up, visit planet.com/explorer . From there, click Sign Up and enter your email address to receive an invitation: Check your email follow the directions to complete the registration process. Trial Account If you need an account in a hurry register for the Trial account , gives you 14 day global access with some limits. Once the trial ends you can still browse using the Planet Explorer and purchase a license or subscription. Education and Research users If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here . If you are at a campus with a campus license and partnership with Planet or if your department or research group has a department license contact your person of interest to get access. Find your API Key Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs. To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key) Registering for a Google Earth Engine Account If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page. Getting Help with Planet and Google Earth Engine Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here You can find the Planet Community Cener here and offcourse the Earth Engine Developers Page","title":"Setting up your Accounts"},{"location":"projects/setup/#registering-for-a-planet-account","text":"What you need first to get started in simply to register for a Planet account.","title":"Registering for a Planet account"},{"location":"projects/setup/#basic-account","text":"To sign up, visit planet.com/explorer . From there, click Sign Up and enter your email address to receive an invitation: Check your email follow the directions to complete the registration process.","title":"Basic Account"},{"location":"projects/setup/#trial-account","text":"If you need an account in a hurry register for the Trial account , gives you 14 day global access with some limits. Once the trial ends you can still browse using the Planet Explorer and purchase a license or subscription.","title":"Trial Account"},{"location":"projects/setup/#education-and-research-users","text":"If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here . If you are at a campus with a campus license and partnership with Planet or if your department or research group has a department license contact your person of interest to get access.","title":"Education and Research users"},{"location":"projects/setup/#find-your-api-key","text":"Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs. To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key)","title":"Find your API Key"},{"location":"projects/setup/#registering-for-a-google-earth-engine-account","text":"If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.","title":"Registering for a Google Earth Engine Account"},{"location":"projects/setup/#getting-help-with-planet-and-google-earth-engine","text":"Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here You can find the Planet Community Cener here and offcourse the Earth Engine Developers Page","title":"Getting Help with Planet and Google Earth Engine"},{"location":"projects/tools/","text":"Data Sources Earth Engine Data Catalog The Earth Engine Data Catalog host over 500+ datasets that have been ingested and a lot more actively curated for easy use. The catalog allows you to look for datasets using keywords as tags so search for water and see what you can find. Open California Dataset Apart from Education and Research account quota of 10,000 sqkm per month, you also have access to free and open data for all of California using the Open California project High Resolution Settlement Layer The Connectivity Lab at Facebook released high resolution population datasets for a couple of countries these are done using high resolution training data at 0.5 m resolution and can be used to understand urban density and movement. This is a 3band product where based on information from Center for International Earth Science Information Network(CIESIN) . I have ingested 13 High Resolution Settlement Layers(HRSL) layers into Google Earth Engine for you to use during the period of the hackathon. You can find the dataset here var hrsl = ee . ImageCollection ( users/samapriya/hrsl ) print ( hrsl ) Microsoft: Computer generated building footprints for the United States and Open AI for Earth In June Microsoft released 125 million Footprints in the US as Open Data, US Buildings Footprints . Though considering the segmentation and classification are performed for Building rooftops as is a better indicator of rooftoop edges. That being said this was also when the discussion and interest in Microsoft Cognitive Toolkit CNTK . You can find more about the research including the papers and the resnet base on their github page Another important and interesting project was the Land Cover Mapping using CNTK and the GeoAI DataScience VM . Head to the [main website] Microsoft: AI for Earth I am including the series of links and useful follow ups posted earlier on Slack to have easy reference Azure Setup Azure AI School Azure Congnitive Services Azure VM Services Student Signup Azure AI school Azure cognitive Services Azure Data Science VM Free Account Setup Azure AI Demo Azure cognitive services demo Azure Geo Data Science VM Azure Doc AI Lab Azure Deep Learning VM Azure SDK and Tools Azure Machine Learning and AI Azure Machine Learning Overview Azure ML Sample Datasets Deep Learning and AI Frameworks Azure ML and data science Tools Samples and Walkthroughs Azure AI Gallery for community samples Satellogic Open Data Head over to Satellogic's data explorer and use the username and password provided to you during the hackathon to access their multispectral and hyperspectral datasets. Tools Planet CLI The planet CLI as mentioned earlier allows you to batch activate, search, download imagery among other things interact with Planet Data API directly. You can find it here or try pip install planet Planet notebooks Planet Labs holds and hosts plenty of jupyter notebooks of you to be able to download, use and analyze Planet data. Earth Engine Python Installation You can access earthengine using python rather than javascript for batch processing. Find installation instructions here Earth Engine CLI This is updated quite frequently earthengine and new releases are released on pypi Satellogic Open Impact Satellogic maintains an open impact repository that holds tutorials to access, download and process data along with introduction to Telluric for analysis. You can find it here satadd: Satellite Data Download Addon I wrote tool a few days back with the idea to harmonize easy access to data that are made available from public and private open data endpoints. This will allow you to download , Planet Labs data, Satellogic Data, query and search Digital Globe data , and query and download Earth Engine imagery as neeeded. You can find the tool here or pip install satadd","title":"Data Sources"},{"location":"projects/tools/#data-sources","text":"","title":"Data Sources"},{"location":"projects/tools/#earth-engine-data-catalog","text":"The Earth Engine Data Catalog host over 500+ datasets that have been ingested and a lot more actively curated for easy use. The catalog allows you to look for datasets using keywords as tags so search for water and see what you can find.","title":"Earth Engine Data Catalog"},{"location":"projects/tools/#open-california-dataset","text":"Apart from Education and Research account quota of 10,000 sqkm per month, you also have access to free and open data for all of California using the Open California project","title":"Open California Dataset"},{"location":"projects/tools/#high-resolution-settlement-layer","text":"The Connectivity Lab at Facebook released high resolution population datasets for a couple of countries these are done using high resolution training data at 0.5 m resolution and can be used to understand urban density and movement. This is a 3band product where based on information from Center for International Earth Science Information Network(CIESIN) . I have ingested 13 High Resolution Settlement Layers(HRSL) layers into Google Earth Engine for you to use during the period of the hackathon. You can find the dataset here var hrsl = ee . ImageCollection ( users/samapriya/hrsl ) print ( hrsl )","title":"High Resolution Settlement Layer"},{"location":"projects/tools/#microsoft-computer-generated-building-footprints-for-the-united-states-and-open-ai-for-earth","text":"In June Microsoft released 125 million Footprints in the US as Open Data, US Buildings Footprints . Though considering the segmentation and classification are performed for Building rooftops as is a better indicator of rooftoop edges. That being said this was also when the discussion and interest in Microsoft Cognitive Toolkit CNTK . You can find more about the research including the papers and the resnet base on their github page Another important and interesting project was the Land Cover Mapping using CNTK and the GeoAI DataScience VM . Head to the [main website]","title":"Microsoft: Computer generated building footprints for the United States and Open AI for Earth"},{"location":"projects/tools/#microsoft-ai-for-earth","text":"I am including the series of links and useful follow ups posted earlier on Slack to have easy reference Azure Setup Azure AI School Azure Congnitive Services Azure VM Services Student Signup Azure AI school Azure cognitive Services Azure Data Science VM Free Account Setup Azure AI Demo Azure cognitive services demo Azure Geo Data Science VM Azure Doc AI Lab Azure Deep Learning VM Azure SDK and Tools Azure Machine Learning and AI Azure Machine Learning Overview Azure ML Sample Datasets Deep Learning and AI Frameworks Azure ML and data science Tools Samples and Walkthroughs Azure AI Gallery for community samples","title":"Microsoft: AI for Earth"},{"location":"projects/tools/#satellogic-open-data","text":"Head over to Satellogic's data explorer and use the username and password provided to you during the hackathon to access their multispectral and hyperspectral datasets.","title":"Satellogic Open Data"},{"location":"projects/tools/#tools","text":"","title":"Tools"},{"location":"projects/tools/#planet-cli","text":"The planet CLI as mentioned earlier allows you to batch activate, search, download imagery among other things interact with Planet Data API directly. You can find it here or try pip install planet","title":"Planet CLI"},{"location":"projects/tools/#planet-notebooks","text":"Planet Labs holds and hosts plenty of jupyter notebooks of you to be able to download, use and analyze Planet data.","title":"Planet notebooks"},{"location":"projects/tools/#earth-engine-python-installation","text":"You can access earthengine using python rather than javascript for batch processing. Find installation instructions here","title":"Earth Engine Python Installation"},{"location":"projects/tools/#earth-engine-cli","text":"This is updated quite frequently earthengine and new releases are released on pypi","title":"Earth Engine CLI"},{"location":"projects/tools/#satellogic-open-impact","text":"Satellogic maintains an open impact repository that holds tutorials to access, download and process data along with introduction to Telluric for analysis. You can find it here","title":"Satellogic Open Impact"},{"location":"projects/tools/#satadd-satellite-data-download-addon","text":"I wrote tool a few days back with the idea to harmonize easy access to data that are made available from public and private open data endpoints. This will allow you to download , Planet Labs data, Satellogic Data, query and search Digital Globe data , and query and download Earth Engine imagery as neeeded. You can find the tool here or pip install satadd","title":"satadd: Satellite Data Download Addon"}]}